{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "intro_md"
      },
      "source": [
        "# SmartProjectionRigFactor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "desc_md"
      },
      "source": [
        "`SmartProjectionRigFactor<CAMERA>` is a generalization of `SmartProjectionPoseFactor` designed for multi-camera systems (rigs).\n",
        "Like other smart factors, it implicitly represents a 3D point landmark observed by multiple cameras.\n",
        "\n",
        "Key differences/features:\n",
        "- **Multi-Camera Rig:** Assumes a fixed rig configuration, where multiple cameras (`CAMERA` instances, which include fixed intrinsics and fixed extrinsics *relative to the rig's body frame*) are defined.\n",
        "- **Pose Variables:** Connects `Pose3` variables representing the pose of the **rig's body frame** in the world.\n",
        "- **Multiple Observations per Pose:** Allows multiple measurements associated with the *same* body pose key, but originating from different cameras within the rig.\n",
        "- **Camera Indexing:** Each measurement must be associated with both a body pose key and a `cameraId` (index) specifying which camera in the rig took the measurement.\n",
        "- **Fixed Calibration/Extrinsics:** The intrinsics and relative extrinsics of the cameras within the rig are assumed fixed.\n",
        "- **`CAMERA` Template:** Can be templated on various camera models (e.g., `PinholeCamera`, `SphericalCamera`), provided they adhere to the expected GTSAM camera concepts.\n",
        "- **`Values` Requirement:** Requires `Pose3` objects (representing the body frame) in the `Values` container.\n",
        "- **Configuration:** Behavior controlled by `SmartProjectionParams`. **Note:** Currently (as of header comment), only supports `HESSIAN` linearization mode and `ZERO_ON_DEGENERACY` mode.\n",
        "\n",
        "**Use Case:** Ideal for visual SLAM with a calibrated multi-camera rig (e.g., stereo rig, multi-fisheye system) where only the rig's pose is optimized.\n",
        "\n",
        "If you are using the factor, please cite:\n",
        "> **L. Carlone, Z. Kira, C. Beall, V. Indelman, F. Dellaert**, \"Eliminating conditionally independent sets in factor graphs: a unifying perspective based on smart factors\", Int. Conf. on Robotics and Automation (ICRA), 2014.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "colab_badge_md"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/borglab/gtsam/blob/develop/gtsam/slam/doc/SmartProjectionRigFactor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pip_code",
        "tags": [
          "remove-cell"
        ]
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    %pip install --quiet gtsam-develop\n",
        "except ImportError:\n",
        "    pass  # Not running on Colab, do nothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "imports_code"
      },
      "outputs": [],
      "source": [
        "import gtsam\n",
        "import numpy as np\n",
        "from gtsam import (\n",
        "    Values,\n",
        "    Point2,\n",
        "    Point3,\n",
        "    Pose3,\n",
        "    Rot3,\n",
        "    NonlinearFactorGraph,\n",
        "    SmartProjectionParams,\n",
        "    SmartProjectionRigFactorPinholePoseCal3_S2,\n",
        "    PinholePoseCal3_S2,\n",
        "    CameraSetPinholePoseCal3_S2,\n",
        "    Cal3_S2,\n",
        ")\n",
        "from gtsam.symbol_shorthand import X  # Key for Pose3 variable (Body Pose)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "create_header_md"
      },
      "source": [
        "## Creating the Rig and Factor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "create_desc_md"
      },
      "source": [
        "1. Define the camera rig configuration: Create a `CameraSet` containing the `CAMERA` objects (with fixed intrinsics and rig-relative extrinsics).\n",
        "2. Create the `SmartProjectionRigFactor` with noise, the rig, and parameters.\n",
        "3. Add measurements, specifying the 2D point, the corresponding **body pose key**, and the **camera ID** within the rig."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "create_example_code"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Smart factor involves 2 measurements from 2 unique poses.\n",
            "SmartFactorRig: SmartProjectionRigFactor: \n",
            " -- Measurement nr 0\n",
            "key: x0\n",
            "cameraId: 0\n",
            "camera in rig:\n",
            ".pose R: [\n",
            "\t1, 0, 0;\n",
            "\t0, 1, 0;\n",
            "\t-0, 0, 1\n",
            "]\n",
            "t: 0.1   0   0\n",
            "camera in rig:\n",
            ".calibration[\n",
            "\t500, 0, 320;\n",
            "\t0, 500, 240;\n",
            "\t0, 0, 1\n",
            "]\n",
            "-- Measurement nr 1\n",
            "key: x0\n",
            "cameraId: 1\n",
            "camera in rig:\n",
            ".pose R: [\n",
            "\t1, 0, 0;\n",
            "\t0, 1, 0;\n",
            "\t-0, 0, 1\n",
            "]\n",
            "t:  0.1 -0.1    0\n",
            "camera in rig:\n",
            ".calibration[\n",
            "\t500, 0, 320;\n",
            "\t0, 500, 240;\n",
            "\t0, 0, 1\n",
            "]\n",
            "-- Measurement nr 2\n",
            "key: x1\n",
            "cameraId: 0\n",
            "camera in rig:\n",
            ".pose R: [\n",
            "\t1, 0, 0;\n",
            "\t0, 1, 0;\n",
            "\t-0, 0, 1\n",
            "]\n",
            "t: 0.1   0   0\n",
            "camera in rig:\n",
            ".calibration[\n",
            "\t500, 0, 320;\n",
            "\t0, 500, 240;\n",
            "\t0, 0, 1\n",
            "]\n",
            "-- Measurement nr 3\n",
            "key: x1\n",
            "cameraId: 1\n",
            "camera in rig:\n",
            ".pose R: [\n",
            "\t1, 0, 0;\n",
            "\t0, 1, 0;\n",
            "\t-0, 0, 1\n",
            "]\n",
            "t:  0.1 -0.1    0\n",
            "camera in rig:\n",
            ".calibration[\n",
            "\t500, 0, 320;\n",
            "\t0, 500, 240;\n",
            "\t0, 0, 1\n",
            "]\n",
            "SmartProjectionFactor\n",
            "linearizationMode: 0\n",
            "triangulationParameters:\n",
            "rankTolerance = 1\n",
            "enableEPI = 0\n",
            "landmarkDistanceThreshold = -1\n",
            "dynamicOutlierRejectionThreshold = -1\n",
            "useLOST = 0\n",
            "noise model\n",
            "\n",
            "result:\n",
            "no point, status = 1\n",
            "\n",
            "SmartFactorBase, z = \n",
            "measurement 0, px = \n",
            "300\n",
            "200\n",
            "noise model = unit (2) \n",
            "measurement 1, px = \n",
            "250\n",
            "201\n",
            "noise model = unit (2) \n",
            "measurement 2, px = \n",
            "310\n",
            "210\n",
            "noise model = unit (2) \n",
            "measurement 3, px = \n",
            "260\n",
            "211\n",
            "noise model = unit (2) \n",
            "  keys = { x0 x1 }\n"
          ]
        }
      ],
      "source": [
        "# 1. Define the Camera Rig\n",
        "K = Cal3_S2(500, 500, 0, 320, 240)\n",
        "# Camera 0: Forward facing, slightly offset\n",
        "body_P_cam0 = Pose3(Rot3.Ypr(0, 0, 0), Point3(0.1, 0, 0))\n",
        "cam0 = PinholePoseCal3_S2(body_P_cam0, K)\n",
        "# Camera 1: Stereo camera, right of cam0\n",
        "body_P_cam1 = Pose3(Rot3.Ypr(0, 0, 0), Point3(0.1, -0.1, 0)) # Baseline 0.1m\n",
        "cam1 = PinholePoseCal3_S2(body_P_cam1, K)\n",
        "\n",
        "rig_cameras = gtsam.CameraSetPinholePoseCal3_S2()\n",
        "rig_cameras.push_back(cam0)\n",
        "rig_cameras.push_back(cam1)\n",
        "\n",
        "# 2. Create the Factor\n",
        "noise_model = gtsam.noiseModel.Isotropic.Sigma(2, 1.0)\n",
        "# Ensure parameters are compatible (HESSIAN, ZERO_ON_DEGENERACY)\n",
        "smart_params = SmartProjectionParams(linMode=gtsam.LinearizationMode.HESSIAN,\n",
        "                                     degMode=gtsam.DegeneracyMode.ZERO_ON_DEGENERACY)\n",
        "\n",
        "# Factor type includes the Camera type\n",
        "smart_factor = SmartProjectionRigFactorPinholePoseCal3_S2(noise_model, rig_cameras, smart_params)\n",
        "\n",
        "# 3. Add measurements\n",
        "# Observation from Body Pose X(0), Camera 0\n",
        "smart_factor.add(Point2(300, 200), X(0), 0)\n",
        "# Observation from Body Pose X(0), Camera 1 (stereo pair?)\n",
        "smart_factor.add(Point2(250, 201), X(0), 1)\n",
        "# Observation from Body Pose X(1), Camera 0\n",
        "smart_factor.add(Point2(310, 210), X(1), 0)\n",
        "# Observation from Body Pose X(1), Camera 1\n",
        "smart_factor.add(Point2(260, 211), X(1), 1)\n",
        "\n",
        "print(f\"Smart factor involves {smart_factor.size()} measurements from {len(smart_factor.keys())} unique poses.\")\n",
        "smart_factor.print(\"SmartFactorRig: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eval_header_md"
      },
      "source": [
        "## Evaluating the Error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eval_desc_md"
      },
      "source": [
        "The `.error(values)` method uses the `Pose3` objects (body poses) from `values` and the fixed rig configuration to triangulate the point and compute the error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eval_example_code"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Triangulated point result:\n",
            "<gtsam.gtsam.TriangulationResult object at 0x117264ff0>\n",
            "\n",
            "Triangulation failed, error calculation depends on degeneracyMode.\n",
            "Error when degenerate: 0.0\n"
          ]
        }
      ],
      "source": [
        "# Create Values containing Body Pose3 objects\n",
        "values = Values()\n",
        "pose0 = Pose3(Rot3.Ypr(0.0, 0.0, 0.0), Point3(0, 0, 0))\n",
        "pose1 = Pose3(Rot3.Ypr(0.1, 0.0, 0.0), Point3(0.5, 0, 0))\n",
        "values.insert(X(0), pose0)\n",
        "values.insert(X(1), pose1)\n",
        "\n",
        "# Triangulate first to see the implicit point\n",
        "# The 'cameras' method internally combines body poses with rig extrinsics\n",
        "point_result = smart_factor.point(values)\n",
        "print(f\"Triangulated point result:\\n{point_result}\")\n",
        "\n",
        "if point_result.valid():\n",
        "   # Calculate error\n",
        "   total_error = smart_factor.error(values)\n",
        "   print(f\"\\nTotal reprojection error (0.5 * sum(err^2/sigma^2)): {total_error:.4f}\")\n",
        "else:\n",
        "   print(\"\\nTriangulation failed, error calculation depends on degeneracyMode.\")\n",
        "   # Since mode is ZERO_ON_DEGENERACY, error should be 0\n",
        "   total_error = smart_factor.error(values)\n",
        "   print(f\"Error when degenerate: {total_error}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py312",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
