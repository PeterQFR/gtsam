{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f851cef5",
   "metadata": {},
   "source": [
    "# DoglegOptimizer Class Documentation\n",
    "\n",
    "*Disclaimer: This documentation was generated by AI and may require human revision for accuracy and completeness.*\n",
    "\n",
    "## Overview\n",
    "\n",
    "The `DoglegOptimizer` class in GTSAM is a specialized optimization algorithm designed for solving nonlinear least squares problems. It implements the Dogleg method, which is a hybrid approach combining the steepest descent and Gauss-Newton methods. This optimizer is particularly effective for problems where the Hessian is difficult to compute or when the initial guess is far from the solution.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "- **Hybrid Approach**: Combines the strengths of both the steepest descent and Gauss-Newton methods.\n",
    "- **Trust Region Method**: Utilizes a trust region to determine the step size, balancing between the accuracy of Gauss-Newton and the robustness of steepest descent.\n",
    "- **Efficient for Nonlinear Problems**: Designed to handle complex nonlinear least squares problems effectively.\n",
    "\n",
    "## Key Methods\n",
    "\n",
    "### Initialization and Setup\n",
    "\n",
    "- **Constructor**: Initializes the optimizer with default or specified parameters.\n",
    "- **setDeltaInitial**: Sets the initial trust region radius, $\\Delta_0$, which influences the step size in the optimization process.\n",
    "\n",
    "### Optimization Process\n",
    "\n",
    "- **optimize**: Executes the optimization process, iteratively refining the solution to minimize the error in the nonlinear least squares problem.\n",
    "- **iterate**: Performs a single iteration of the Dogleg optimization, updating the current estimate based on the trust region and the computed step.\n",
    "\n",
    "### Result Evaluation\n",
    "\n",
    "- **error**: Computes the error of the current estimate, providing a measure of how well the current solution fits the problem constraints.\n",
    "- **values**: Returns the optimized values after the optimization process is complete.\n",
    "\n",
    "### Trust Region Management\n",
    "\n",
    "- **getDelta**: Retrieves the current trust region radius, $\\Delta$, which is crucial for understanding the optimizer's step size decisions.\n",
    "- **setDelta**: Manually sets the trust region radius, allowing for fine-tuned control over the optimization process.\n",
    "\n",
    "## Mathematical Formulation\n",
    "\n",
    "The Dogleg method is characterized by its use of two distinct steps:\n",
    "\n",
    "1. **Cauchy Point**: The steepest descent direction, calculated as:\n",
    "   $$ p_u = -\\alpha \\nabla f(x) $$\n",
    "   where $\\alpha$ is a scalar step size.\n",
    "\n",
    "2. **Gauss-Newton Step**: The solution to the linearized problem, providing a more accurate but computationally expensive step:\n",
    "   $$ p_{gn} = -(J^T J)^{-1} J^T r $$\n",
    "   where $J$ is the Jacobian matrix and $r$ is the residual vector.\n",
    "\n",
    "The Dogleg step, $p_{dl}$, is a combination of these two steps, determined by the trust region radius $\\Delta$.\n",
    "\n",
    "## Usage Considerations\n",
    "\n",
    "- **Initial Guess**: The performance of the Dogleg optimizer can be sensitive to the initial guess. A good initial estimate can significantly speed up convergence.\n",
    "- **Parameter Tuning**: The choice of the initial trust region radius and other parameters can affect the convergence rate and stability of the optimization.\n",
    "\n",
    "The `DoglegOptimizer` is a powerful tool for solving nonlinear optimization problems, particularly when dealing with large-scale systems where computational efficiency is crucial. By leveraging the hybrid approach of the Dogleg method, it provides a robust solution capable of handling a wide range of problem complexities."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
